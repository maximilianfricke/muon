# Basic training configuration for TinyViT on CIFAR-10

experiment:
  name: "basic_training_vit_cifar10"
  seed: 42
  device: "auto"  

dataset:
  name: "cifar10"
  root: "./data"
  full_batch: true  
  train_subset_size: 2000  

model:
  type: "tiny_vit"
  config:
    img_size: 32
    patch_size: 4
    num_classes: 10
    embed_dim: 128
    depth: 4
    num_heads: 4
    mlp_ratio: 4.0
    dropout: 0.0

optimizer:
  type: "muon" 
  config:
    lr: 0.02
    momentum: 0.95
    ns_depth: 5
    use_rms: false
    use_orthogonalization: true
    weight_decay: 0.0
    adamw_lr: 0.001  

training:
  num_epochs: 50
  loss_fn: "cross_entropy"

logging:
  wandb:
    enabled: false
  save_dir: "./results/basic_training"
  save_frequency: 10  
